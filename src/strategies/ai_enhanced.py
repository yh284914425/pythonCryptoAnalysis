"""
ğŸ¤– AIå¢å¼ºç³»ç»Ÿæ¨¡å—
AI Enhanced System Module

åŒ…å«Transformeré¢„æµ‹æ¨¡å‹ã€å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ã€æƒ…ç»ªåˆ†æç­‰AIåŠŸèƒ½
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
import torch
import torch.nn as nn
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import requests
import json
from datetime import datetime, timedelta
import logging
from .config import AIConfig, API_KEYS

class TransformerPricePredictor:
    """Transformerä»·æ ¼é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, config: AIConfig):
        self.config = config
        self.model = None
        self.scaler = None
        self.sequence_length = 168  # 7å¤©*24å°æ—¶
        self.feature_dim = 10  # ä»·æ ¼ã€æˆäº¤é‡ã€æŠ€æœ¯æŒ‡æ ‡ç­‰ç‰¹å¾
        
    def build_model(self):
        """æ„å»ºTransformeræ¨¡å‹"""
        class PriceTransformer(nn.Module):
            def __init__(self, feature_dim, d_model=128, nhead=8, num_layers=4):
                super().__init__()
                self.feature_dim = feature_dim
                self.d_model = d_model
                
                # è¾“å…¥æŠ•å½±å±‚
                self.input_projection = nn.Linear(feature_dim, d_model)
                
                # ä½ç½®ç¼–ç 
                self.positional_encoding = nn.Parameter(
                    torch.randn(1000, d_model) * 0.1
                )
                
                # Transformerç¼–ç å™¨
                encoder_layer = nn.TransformerEncoderLayer(
                    d_model=d_model,
                    nhead=nhead,
                    dim_feedforward=512,
                    dropout=0.1,
                    batch_first=True
                )
                self.transformer = nn.TransformerEncoder(
                    encoder_layer, 
                    num_layers=num_layers
                )
                
                # è¾“å‡ºå±‚
                self.output_projection = nn.Sequential(
                    nn.Linear(d_model, 64),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(64, 1)  # é¢„æµ‹ä»·æ ¼å˜åŒ–
                )
                
            def forward(self, x):
                batch_size, seq_len, _ = x.shape
                
                # è¾“å…¥æŠ•å½±
                x = self.input_projection(x)
                
                # æ·»åŠ ä½ç½®ç¼–ç 
                x = x + self.positional_encoding[:seq_len].unsqueeze(0)
                
                # Transformerç¼–ç 
                x = self.transformer(x)
                
                # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
                x = x[:, -1, :]
                
                # é¢„æµ‹è¾“å‡º
                return self.output_projection(x)
        
        self.model = PriceTransformer(self.feature_dim)
        return self.model
    
    def prepare_features(self, price_data: pd.DataFrame, 
                        technical_indicators: Dict, 
                        onchain_data: Dict) -> np.ndarray:
        """å‡†å¤‡æ¨¡å‹è¾“å…¥ç‰¹å¾"""
        features = []
        
        # ä»·æ ¼ç‰¹å¾ (æ ‡å‡†åŒ–)
        price_features = price_data[['open', 'high', 'low', 'close', 'volume']].values
        price_features = (price_features - price_features.mean(axis=0)) / price_features.std(axis=0)
        features.append(price_features)
        
        # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        if 'kdj' in technical_indicators:
            kdj_features = np.column_stack([
                technical_indicators['kdj']['K'].values,
                technical_indicators['kdj']['D'].values,
                technical_indicators['kdj']['J'].values
            ])
            features.append(kdj_features)
        
        # MACDç‰¹å¾
        if 'macd' in technical_indicators:
            macd_features = np.column_stack([
                technical_indicators['macd']['macd'].values,
                technical_indicators['macd']['signal'].values
            ])
            features.append(macd_features)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        all_features = np.concatenate(features, axis=1)
        
        # ç¡®ä¿ç‰¹å¾ç»´åº¦æ­£ç¡®
        if all_features.shape[1] != self.feature_dim:
            # å¡«å……æˆ–æˆªæ–­åˆ°ç›®æ ‡ç»´åº¦
            if all_features.shape[1] < self.feature_dim:
                padding = np.zeros((all_features.shape[0], 
                                  self.feature_dim - all_features.shape[1]))
                all_features = np.concatenate([all_features, padding], axis=1)
            else:
                all_features = all_features[:, :self.feature_dim]
        
        return all_features
    
    def predict_price_probability(self, features: np.ndarray) -> Dict[str, float]:
        """
        é¢„æµ‹æœªæ¥ä»·æ ¼æ¦‚ç‡åˆ†å¸ƒ
        
        Returns:
            åŒ…å«ä¸Šæ¶¨/ä¸‹è·Œæ¦‚ç‡çš„å­—å…¸
        """
        if self.model is None:
            self.build_model()
            # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥åŠ è½½é¢„è®­ç»ƒçš„æƒé‡
            # self.model.load_state_dict(torch.load('model_weights.pth'))
        
        self.model.eval()
        
        # å‡†å¤‡è¾“å…¥åºåˆ—
        if len(features) < self.sequence_length:
            # å¦‚æœæ•°æ®ä¸è¶³ï¼Œç”¨é›¶å¡«å……
            padding = np.zeros((self.sequence_length - len(features), self.feature_dim))
            features = np.concatenate([padding, features], axis=0)
        else:
            features = features[-self.sequence_length:]
        
        # è½¬æ¢ä¸ºå¼ é‡
        input_tensor = torch.FloatTensor(features).unsqueeze(0)
        
        with torch.no_grad():
            prediction = self.model(input_tensor)
            
        # å°†é¢„æµ‹è½¬æ¢ä¸ºæ¦‚ç‡
        price_change = prediction.item()
        
        # ä½¿ç”¨sigmoidå‡½æ•°å°†ä»·æ ¼å˜åŒ–è½¬æ¢ä¸ºä¸Šæ¶¨æ¦‚ç‡
        up_probability = 1 / (1 + np.exp(-price_change))
        down_probability = 1 - up_probability
        
        confidence = abs(price_change)  # é¢„æµ‹ç½®ä¿¡åº¦
        
        return {
            'up_probability': float(up_probability),
            'down_probability': float(down_probability),
            'confidence': float(min(confidence, 1.0)),
            'raw_prediction': float(price_change)
        }

class SentimentAnalyzer:
    """æƒ…ç»ªåˆ†æå™¨"""
    
    def __init__(self, config: AIConfig):
        self.config = config
        self.twitter_api_key = API_KEYS.get('TWITTER_API_KEY')
        
        # åˆå§‹åŒ–æƒ…ç»ªåˆ†ææ¨¡å‹
        try:
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model="ProsusAI/finbert",  # é‡‘èé¢†åŸŸä¸“ç”¨æ¨¡å‹
                tokenizer="ProsusAI/finbert"
            )
        except:
            # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
            self.sentiment_pipeline = None
            logging.warning("FinBERT model not available, using simplified sentiment analysis")
    
    def analyze_twitter_sentiment(self, query: str = "Bitcoin BTC", 
                                 count: int = 100) -> Dict[str, float]:
        """åˆ†æTwitteræƒ…ç»ª"""
        if not self.twitter_api_key:
            return self._get_mock_sentiment()
        
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨Twitter APIè·å–æ¨æ–‡
            # tweets = self._fetch_tweets(query, count)
            tweets = self._get_mock_tweets()  # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            
            return self._analyze_tweet_sentiments(tweets)
            
        except Exception as e:
            logging.error(f"Twitter sentiment analysis failed: {e}")
            return self._get_mock_sentiment()
    
    def _get_mock_tweets(self) -> List[str]:
        """è·å–æ¨¡æ‹Ÿæ¨æ–‡æ•°æ®"""
        mock_tweets = [
            "Bitcoin is going to the moon! ğŸš€",
            "BTC looking bearish, time to sell",
            "Hodling strong, diamond hands ğŸ’",
            "Crypto market is crashing, panic selling",
            "Bitcoin adoption is accelerating, bullish long term",
            "Whales are accumulating, bottom might be in",
            "Fear and greed index shows extreme fear",
            "DeFi is the future, Ethereum leading the way",
            "Regulatory clarity needed for crypto growth",
            "Bitcoin hash rate hitting new highs"
        ]
        return mock_tweets
    
    def _analyze_tweet_sentiments(self, tweets: List[str]) -> Dict[str, float]:
        """åˆ†ææ¨æ–‡æƒ…ç»ª"""
        if not self.sentiment_pipeline:
            return self._get_mock_sentiment()
        
        sentiments = []
        for tweet in tweets:
            try:
                result = self.sentiment_pipeline(tweet)[0]
                score = result['score']
                label = result['label'].lower()
                
                if label == 'positive':
                    sentiments.append(score)
                elif label == 'negative':
                    sentiments.append(-score)
                else:
                    sentiments.append(0)
                    
            except Exception as e:
                logging.warning(f"Failed to analyze tweet sentiment: {e}")
                continue
        
        if not sentiments:
            return self._get_mock_sentiment()
        
        # è®¡ç®—æƒ…ç»ªç»Ÿè®¡
        avg_sentiment = np.mean(sentiments)
        sentiment_std = np.std(sentiments)
        
        # è½¬æ¢ä¸ºææƒ§è´ªå©ªæŒ‡æ•° (0-100)
        fear_greed_index = max(0, min(100, (avg_sentiment + 1) * 50))
        
        return {
            'fear_greed_index': fear_greed_index,
            'average_sentiment': avg_sentiment,
            'sentiment_volatility': sentiment_std,
            'bullish_ratio': len([s for s in sentiments if s > 0.1]) / len(sentiments),
            'bearish_ratio': len([s for s in sentiments if s < -0.1]) / len(sentiments),
            'neutral_ratio': len([s for s in sentiments if -0.1 <= s <= 0.1]) / len(sentiments)
        }
    
    def _get_mock_sentiment(self) -> Dict[str, float]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæƒ…ç»ªæ•°æ®"""
        np.random.seed(int(datetime.now().timestamp()) % 1000)
        fear_greed_index = np.random.uniform(10, 90)
        
        return {
            'fear_greed_index': fear_greed_index,
            'average_sentiment': (fear_greed_index - 50) / 50,
            'sentiment_volatility': np.random.uniform(0.1, 0.5),
            'bullish_ratio': np.random.uniform(0.2, 0.6),
            'bearish_ratio': np.random.uniform(0.2, 0.6),
            'neutral_ratio': np.random.uniform(0.1, 0.4)
        }
    
    def get_sentiment_signal(self, sentiment_data: Dict[str, float]) -> Dict[str, any]:
        """æ ¹æ®æƒ…ç»ªæ•°æ®ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        fear_greed_index = sentiment_data['fear_greed_index']
        
        if fear_greed_index < self.config.sentiment_fear_threshold:
            return {
                'signal': 'bullish',
                'strength': 'strong',
                'description': f'æåº¦ææ…Œ(FGI: {fear_greed_index:.0f})ï¼Œå¼ºä¹°å…¥ä¿¡å·'
            }
        elif fear_greed_index > self.config.sentiment_greed_threshold:
            return {
                'signal': 'bearish', 
                'strength': 'strong',
                'description': f'æåº¦è´ªå©ª(FGI: {fear_greed_index:.0f})ï¼Œå¼ºå–å‡ºä¿¡å·'
            }
        elif fear_greed_index < 25:
            return {
                'signal': 'bullish',
                'strength': 'medium',
                'description': f'ææ…Œæƒ…ç»ª(FGI: {fear_greed_index:.0f})ï¼Œä¹°å…¥ä¿¡å·'
            }
        elif fear_greed_index > 75:
            return {
                'signal': 'bearish',
                'strength': 'medium', 
                'description': f'è´ªå©ªæƒ…ç»ª(FGI: {fear_greed_index:.0f})ï¼Œå–å‡ºä¿¡å·'
            }
        else:
            return {
                'signal': 'neutral',
                'strength': 'weak',
                'description': f'æƒ…ç»ªä¸­æ€§(FGI: {fear_greed_index:.0f})'
            }

class ReinforcementLearningOptimizer:
    """å¼ºåŒ–å­¦ä¹ å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, config: AIConfig):
        self.config = config
        self.q_table = {}  # ç®€åŒ–çš„Qè¡¨
        self.learning_rate = config.rl_learning_rate
        self.epsilon = 0.1  # æ¢ç´¢ç‡
        self.state_history = []
        self.action_history = []
        self.reward_history = []
    
    def get_state(self, market_data: Dict) -> str:
        """å°†å¸‚åœºæ•°æ®è½¬æ¢ä¸ºçŠ¶æ€è¡¨ç¤º"""
        # ç®€åŒ–çš„çŠ¶æ€è¡¨ç¤º
        price_trend = "up" if market_data.get('price_change', 0) > 0 else "down"
        volatility = "high" if market_data.get('volatility', 0) > 0.05 else "low"
        volume = "high" if market_data.get('volume_ratio', 1) > 1.5 else "low"
        
        return f"{price_trend}_{volatility}_{volume}"
    
    def choose_action(self, state: str, available_actions: List[str]) -> str:
        """ä½¿ç”¨Îµ-è´ªå©ªç­–ç•¥é€‰æ‹©åŠ¨ä½œ"""
        if np.random.random() < self.epsilon:
            # æ¢ç´¢ï¼šéšæœºé€‰æ‹©
            return np.random.choice(available_actions)
        else:
            # åˆ©ç”¨ï¼šé€‰æ‹©æœ€ä¼˜åŠ¨ä½œ
            if state not in self.q_table:
                self.q_table[state] = {action: 0.0 for action in available_actions}
            
            return max(self.q_table[state], key=self.q_table[state].get)
    
    def update_q_value(self, state: str, action: str, reward: float, next_state: str):
        """æ›´æ–°Qå€¼"""
        if state not in self.q_table:
            self.q_table[state] = {}
        if action not in self.q_table[state]:
            self.q_table[state][action] = 0.0
        
        if next_state not in self.q_table:
            self.q_table[next_state] = {}
        
        # Q-learningæ›´æ–°è§„åˆ™
        old_q = self.q_table[state][action]
        next_max_q = max(self.q_table[next_state].values()) if self.q_table[next_state] else 0
        
        new_q = old_q + self.learning_rate * (reward + 0.9 * next_max_q - old_q)
        self.q_table[state][action] = new_q
    
    def get_optimized_parameters(self, current_state: str) -> Dict[str, float]:
        """è·å–ä¼˜åŒ–åçš„ç­–ç•¥å‚æ•°"""
        # æ ¹æ®Qè¡¨é€‰æ‹©æœ€ä¼˜å‚æ•°ç»„åˆ
        parameter_actions = [
            'conservative', 'moderate', 'aggressive'
        ]
        
        optimal_action = self.choose_action(current_state, parameter_actions)
        
        # è¿”å›å¯¹åº”çš„å‚æ•°è®¾ç½®
        parameter_sets = {
            'conservative': {
                'position_size_multiplier': 0.8,
                'stop_loss_multiplier': 0.8,
                'signal_threshold': 75
            },
            'moderate': {
                'position_size_multiplier': 1.0,
                'stop_loss_multiplier': 1.0,
                'signal_threshold': 65
            },
            'aggressive': {
                'position_size_multiplier': 1.2,
                'stop_loss_multiplier': 1.2,
                'signal_threshold': 55
            }
        }
        
        return parameter_sets.get(optimal_action, parameter_sets['moderate'])

class AISignalFilter:
    """AIä¿¡å·è¿‡æ»¤å™¨"""
    
    def __init__(self, config: AIConfig):
        self.config = config
        self.price_predictor = TransformerPricePredictor(config)
        self.sentiment_analyzer = SentimentAnalyzer(config)
        self.rl_optimizer = ReinforcementLearningOptimizer(config)
        
    def filter_trading_signal(self, 
                            raw_signal: Dict,
                            market_data: pd.DataFrame,
                            technical_indicators: Dict,
                            onchain_data: Dict) -> Dict[str, any]:
        """
        ä½¿ç”¨AIæ¨¡å‹è¿‡æ»¤äº¤æ˜“ä¿¡å·
        
        Args:
            raw_signal: åŸå§‹æŠ€æœ¯åˆ†æä¿¡å·
            market_data: å¸‚åœºæ•°æ®
            technical_indicators: æŠ€æœ¯æŒ‡æ ‡
            onchain_data: é“¾ä¸Šæ•°æ®
            
        Returns:
            è¿‡æ»¤åçš„å¢å¼ºä¿¡å·
        """
        
        # 1. Transformerä»·æ ¼é¢„æµ‹
        features = self.price_predictor.prepare_features(
            market_data, technical_indicators, onchain_data
        )
        price_prediction = self.price_predictor.predict_price_probability(features)
        
        # 2. æƒ…ç»ªåˆ†æ
        sentiment_data = self.sentiment_analyzer.analyze_twitter_sentiment()
        sentiment_signal = self.sentiment_analyzer.get_sentiment_signal(sentiment_data)
        
        # 3. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–
        current_state = self.rl_optimizer.get_state({
            'price_change': market_data['close'].pct_change().iloc[-1],
            'volatility': market_data['close'].pct_change().std(),
            'volume_ratio': market_data['volume'].iloc[-1] / market_data['volume'].mean()
        })
        optimized_params = self.rl_optimizer.get_optimized_parameters(current_state)
        
        # 4. ç»¼åˆè¯„ä¼°å’Œè¿‡æ»¤
        enhanced_signal = self._combine_ai_signals(
            raw_signal, price_prediction, sentiment_signal, optimized_params
        )
        
        return enhanced_signal
    
    def _combine_ai_signals(self, 
                           raw_signal: Dict,
                           price_prediction: Dict,
                           sentiment_signal: Dict,
                           optimized_params: Dict) -> Dict[str, any]:
        """ç»¼åˆAIä¿¡å·"""
        
        # AIç¡®è®¤é€»è¾‘
        ai_confirmation = True
        confidence_boost = 0
        
        # ä»·æ ¼é¢„æµ‹ç¡®è®¤
        if raw_signal.get('signal_type') == 'bullish':
            if price_prediction['up_probability'] > self.config.model_confidence_threshold:
                confidence_boost += 0.2
            else:
                ai_confirmation = False
                
        elif raw_signal.get('signal_type') == 'bearish':
            if price_prediction['down_probability'] > self.config.model_confidence_threshold:
                confidence_boost += 0.2
            else:
                ai_confirmation = False
        
        # æƒ…ç»ªåˆ†æç¡®è®¤
        if sentiment_signal['signal'] == raw_signal.get('signal_type'):
            if sentiment_signal['strength'] == 'strong':
                confidence_boost += 0.15
            else:
                confidence_boost += 0.1
        
        # è®¡ç®—æœ€ç»ˆä¿¡å·å¼ºåº¦
        original_strength = raw_signal.get('strength_score', 0.5)
        final_strength = min(1.0, original_strength + confidence_boost)
        
        return {
            'signal_type': raw_signal.get('signal_type'),
            'original_strength': original_strength,
            'ai_enhanced_strength': final_strength,
            'ai_confirmation': ai_confirmation,
            'price_prediction': price_prediction,
            'sentiment_analysis': sentiment_signal,
            'optimized_parameters': optimized_params,
            'recommendation': 'execute' if ai_confirmation and final_strength > 0.7 else 'hold',
            'confidence': final_strength
        }

if __name__ == "__main__":
    # æµ‹è¯•AIå¢å¼ºæ¨¡å—
    from .config import AIConfig
    
    print("ğŸ¤– AIå¢å¼ºç³»ç»Ÿæµ‹è¯•")
    
    # åˆå§‹åŒ–é…ç½®
    config = AIConfig()
    ai_filter = AISignalFilter(config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2024-01-01', periods=200, freq='1H')
    np.random.seed(42)
    prices = 50000 + np.cumsum(np.random.randn(200) * 100)
    
    test_market_data = pd.DataFrame({
        'open': prices + np.random.randn(200) * 50,
        'high': prices + np.abs(np.random.randn(200)) * 100,
        'low': prices - np.abs(np.random.randn(200)) * 100,
        'close': prices,
        'volume': np.random.randint(1000, 10000, 200)
    }, index=dates)
    
    # æ¨¡æ‹ŸåŸå§‹ä¿¡å·
    raw_signal = {
        'signal_type': 'bullish',
        'strength_score': 0.65,
        'source': 'technical_analysis'
    }
    
    # æµ‹è¯•AIè¿‡æ»¤
    enhanced_signal = ai_filter.filter_trading_signal(
        raw_signal=raw_signal,
        market_data=test_market_data,
        technical_indicators={},
        onchain_data={}
    )
    
    print(f"\nğŸ“Š AIä¿¡å·è¿‡æ»¤ç»“æœ:")
    print(f"åŸå§‹ä¿¡å·å¼ºåº¦: {enhanced_signal['original_strength']:.2f}")
    print(f"AIå¢å¼ºå¼ºåº¦: {enhanced_signal['ai_enhanced_strength']:.2f}")
    print(f"AIç¡®è®¤: {enhanced_signal['ai_confirmation']}")
    print(f"æœ€ç»ˆæ¨è: {enhanced_signal['recommendation']}")
    print(f"ç½®ä¿¡åº¦: {enhanced_signal['confidence']:.2f}")
    
    print("\nâœ… AIå¢å¼ºç³»ç»Ÿæµ‹è¯•å®Œæˆ") 